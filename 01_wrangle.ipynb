{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f135b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None) #to supress column truncation\n",
    "# pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d88b7",
   "metadata": {},
   "source": [
    "# Importing data and reading to dfs to combine into single df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5326b2ce",
   "metadata": {},
   "source": [
    "### Reading the `311_service_data` csv to a df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b071492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>OPENEDDATETIME</th>\n",
       "      <th>SLA_Date</th>\n",
       "      <th>CLOSEDDATETIME</th>\n",
       "      <th>Late (Yes/No)</th>\n",
       "      <th>Dept</th>\n",
       "      <th>REASONNAME</th>\n",
       "      <th>TYPENAME</th>\n",
       "      <th>CaseStatus</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>OBJECTDESC</th>\n",
       "      <th>Council District</th>\n",
       "      <th>XCOORD</th>\n",
       "      <th>YCOORD</th>\n",
       "      <th>Report Starting Date</th>\n",
       "      <th>Report Ending Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graffiti</td>\n",
       "      <td>1010444245</td>\n",
       "      <td>8/15/2012</td>\n",
       "      <td>8/30/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>Graffiti</td>\n",
       "      <td>Graffiti Public Property</td>\n",
       "      <td>Open</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>600  NOGALITOS ST, San Antonio, 78204</td>\n",
       "      <td>5</td>\n",
       "      <td>2125683.0</td>\n",
       "      <td>13695548.0</td>\n",
       "      <td>1/15/2021</td>\n",
       "      <td>1/15/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Property Maintenance</td>\n",
       "      <td>1010888252</td>\n",
       "      <td>6/6/2013</td>\n",
       "      <td>8/9/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>Code Enforcement (IntExp)</td>\n",
       "      <td>Alley-Way Maintenance</td>\n",
       "      <td>Open</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>6043  CASTLE QUEEN, San Antonio, 78218</td>\n",
       "      <td>2</td>\n",
       "      <td>2169702.0</td>\n",
       "      <td>13725769.0</td>\n",
       "      <td>1/15/2021</td>\n",
       "      <td>1/15/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category      CASEID OPENEDDATETIME   SLA_Date CLOSEDDATETIME  \\\n",
       "0              Graffiti  1010444245      8/15/2012  8/30/2012            NaN   \n",
       "1  Property Maintenance  1010888252       6/6/2013   8/9/2013            NaN   \n",
       "\n",
       "  Late (Yes/No)                       Dept                 REASONNAME  \\\n",
       "0           YES  Code Enforcement Services                   Graffiti   \n",
       "1           YES  Code Enforcement Services  Code Enforcement (IntExp)   \n",
       "\n",
       "                   TYPENAME CaseStatus    SourceID  \\\n",
       "0  Graffiti Public Property       Open  Web Portal   \n",
       "1     Alley-Way Maintenance       Open  Web Portal   \n",
       "\n",
       "                               OBJECTDESC  Council District     XCOORD  \\\n",
       "0   600  NOGALITOS ST, San Antonio, 78204                 5  2125683.0   \n",
       "1  6043  CASTLE QUEEN, San Antonio, 78218                 2  2169702.0   \n",
       "\n",
       "       YCOORD Report Starting Date Report Ending Date  \n",
       "0  13695548.0            1/15/2021          1/15/2022  \n",
       "1  13725769.0            1/15/2021          1/15/2022  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_data = pd.read_csv('311_service_data.csv')\n",
    "service_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69c32e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521590, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a36a44",
   "metadata": {},
   "source": [
    "### Reading the `med_incomebyzip` csv to a df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b38c205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Location</th>\n",
       "      <th>Population</th>\n",
       "      <th>avg_household_income</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78261</td>\n",
       "      <td>29.705479, -98.402849</td>\n",
       "      <td>1,119</td>\n",
       "      <td>$92,154.00</td>\n",
       "      <td>29.705479</td>\n",
       "      <td>-98.402849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78258</td>\n",
       "      <td>29.647111, -98.500768</td>\n",
       "      <td>17,355</td>\n",
       "      <td>$91,509.00</td>\n",
       "      <td>29.647111</td>\n",
       "      <td>-98.500768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zip Code               Location Population avg_household_income       Lat   \\\n",
       "0     78261  29.705479, -98.402849      1,119           $92,154.00  29.705479   \n",
       "1     78258  29.647111, -98.500768     17,355           $91,509.00  29.647111   \n",
       "\n",
       "        Long  \n",
       "0 -98.402849  \n",
       "1 -98.500768  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_incomebyzip = pd.read_csv('med_incomebyzip.csv').drop(columns = ['#'])\n",
    "med_incomebyzip.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e5737c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_incomebyzip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37b9bf",
   "metadata": {},
   "source": [
    "### I could do an inner join on zip code and combine the dataframes. \n",
    "First, I need to modify the `OBJECTDESCR` address values in the `service_data` df to only show the zip codes. I can do this by calling the last 5 (-5) values.\n",
    "- Some addresses do not have a zip code. The inner join will eliminate those values from the joined df. Given additional time, I will come back and look up the zip codes for the address that do not have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283412b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>OPENEDDATETIME</th>\n",
       "      <th>SLA_Date</th>\n",
       "      <th>CLOSEDDATETIME</th>\n",
       "      <th>Late (Yes/No)</th>\n",
       "      <th>Dept</th>\n",
       "      <th>REASONNAME</th>\n",
       "      <th>TYPENAME</th>\n",
       "      <th>CaseStatus</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>Council District</th>\n",
       "      <th>XCOORD</th>\n",
       "      <th>YCOORD</th>\n",
       "      <th>Report Starting Date</th>\n",
       "      <th>Report Ending Date</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graffiti</td>\n",
       "      <td>1010444245</td>\n",
       "      <td>8/15/2012</td>\n",
       "      <td>8/30/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>Graffiti</td>\n",
       "      <td>Graffiti Public Property</td>\n",
       "      <td>Open</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>5</td>\n",
       "      <td>2125683.0</td>\n",
       "      <td>13695548.0</td>\n",
       "      <td>1/15/2021</td>\n",
       "      <td>1/15/2022</td>\n",
       "      <td>78204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Property Maintenance</td>\n",
       "      <td>1010888252</td>\n",
       "      <td>6/6/2013</td>\n",
       "      <td>8/9/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>Code Enforcement (IntExp)</td>\n",
       "      <td>Alley-Way Maintenance</td>\n",
       "      <td>Open</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>2</td>\n",
       "      <td>2169702.0</td>\n",
       "      <td>13725769.0</td>\n",
       "      <td>1/15/2021</td>\n",
       "      <td>1/15/2022</td>\n",
       "      <td>78218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category      CASEID OPENEDDATETIME   SLA_Date CLOSEDDATETIME  \\\n",
       "0              Graffiti  1010444245      8/15/2012  8/30/2012            NaN   \n",
       "1  Property Maintenance  1010888252       6/6/2013   8/9/2013            NaN   \n",
       "\n",
       "  Late (Yes/No)                       Dept                 REASONNAME  \\\n",
       "0           YES  Code Enforcement Services                   Graffiti   \n",
       "1           YES  Code Enforcement Services  Code Enforcement (IntExp)   \n",
       "\n",
       "                   TYPENAME CaseStatus    SourceID  Council District  \\\n",
       "0  Graffiti Public Property       Open  Web Portal                 5   \n",
       "1     Alley-Way Maintenance       Open  Web Portal                 2   \n",
       "\n",
       "      XCOORD      YCOORD Report Starting Date Report Ending Date    zip  \n",
       "0  2125683.0  13695548.0            1/15/2021          1/15/2022  78204  \n",
       "1  2169702.0  13725769.0            1/15/2021          1/15/2022  78218  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a for loop that will loop through each address value and give me the last 5 character in the string \n",
    "zips = []\n",
    "\n",
    "for address in service_data.OBJECTDESC:\n",
    "    zips.append(address[-5:])\n",
    "    \n",
    "# creating a new zip column for the df with those values\n",
    "service_data['zip'] = zips\n",
    "    \n",
    "# dropping the OBJECTDESC address column from the df\n",
    "service_data.drop(columns = ['OBJECTDESC'], inplace = True)\n",
    "service_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0e7b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the following line of code will allow me to see all of the rows so I can look at the nonnumeric values\n",
    "\n",
    "\n",
    "# nonzips = []\n",
    "# for value in service_data.zip:\n",
    "#     if value[0] != '7':\n",
    "#         nonzips.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6e41d",
   "metadata": {},
   "source": [
    ">### I am getting an error here: it apppears that the columns I am trying to merge on do not have the same dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8ed532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f9dfe7122ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m service_data.merge(med_incomebyzip, how = 'inner',\n\u001b[0m\u001b[1;32m      2\u001b[0m                   left_on = 'zip', right_on = 'Zip Code')\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   8193\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8195\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   8196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8197\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[0;32m---> 74\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 ):\n\u001b[0;32m-> 1193\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "service_data.merge(med_incomebyzip, how = 'inner',\n",
    "                  left_on = 'zip', right_on = 'Zip Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f6e9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_data.zip.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c899d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_incomebyzip['Zip Code'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eefabb9",
   "metadata": {},
   "source": [
    "#### The first dataframe's zip codes are objects and the second's are integers\n",
    ">#### Since these will need to be objects I will convert the second dataframes zip codes to object values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing series dtype from int to object\n",
    "med_incomebyzip['Zip Code'] = med_incomebyzip['Zip Code'].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_incomebyzip['Zip Code'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(med_incomebyzip['Zip Code'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df372269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Zip_Code = []\n",
    "\n",
    "for value in med_incomebyzip['Zip Code']:\n",
    "    Zip_Code.append(str(value))\n",
    "    \n",
    "Zip_Code[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ca3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing int Zip Code column with strings\n",
    "med_incomebyzip['Zip Code'] = Zip_Code\n",
    "type(med_incomebyzip['Zip Code'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b53166",
   "metadata": {},
   "source": [
    "### Going to try the merge again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87eeac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = service_data.merge(med_incomebyzip, how = 'inner',\n",
    "                  left_on = 'zip', right_on = 'Zip Code').drop(columns = ['Zip Code'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578329b",
   "metadata": {},
   "source": [
    "### And we have a merged df!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d33c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb76d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93067fa0",
   "metadata": {},
   "source": [
    "# General Info About the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {df.shape[0]} observations and {df.shape[1]} columns in the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d35000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Report Starting Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721aef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Report Ending Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb9ab1c",
   "metadata": {},
   "source": [
    "### I will go ahead and start removing some of the columns I know I will not be using\n",
    "I will also lowercase the columns names here as well\n",
    "- `TYPENAME` pretty similar to `REASONNAME` and accepts multiple values\n",
    "- `XCOORD` and `YCOORD` unsure of coordinate system used? Does not appear to coorespond with lat/long, dropping for now\n",
    "- `Report Starting Date` and `Report Ending Date` since they have only x1 value/are the same for each report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.str.replace(' ', '').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6501b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['TYPENAME', 'XCOORD', 'YCOORD', 'Report Starting Date', 'Report Ending Date']\n",
    "\n",
    "df.drop(columns = cols_to_drop, inplace = True)\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '').str.lower()\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9edcc2",
   "metadata": {},
   "source": [
    "### And while I am it, I will do a little more column name cleanup and make them more readable based on the data dictionary description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e02d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {'caseid':'case_ref_num', \n",
    "'openeddatetime':'case_open', \n",
    "'sla_date':'sla_due', \n",
    "'closeddatetime':'case_close', \n",
    "'late(yes/no)':'sla_late', \n",
    "'reasonname':'dept_div',  \n",
    "'casestatus':'case_status', \n",
    "'councildistrict':'council_distr', \n",
    "'avg_household_income':'avg_inc'}\n",
    "\n",
    "df.rename(columns = cols_to_rename, inplace = True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae6a49",
   "metadata": {},
   "source": [
    "### Looking at dtypes for each column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to be appended in for loop\n",
    "obj_list = []\n",
    "num_list = []\n",
    "bool_list = []\n",
    "\n",
    "# for loop to append df columns to corresponding lists\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'O':\n",
    "        obj_list.append(col)\n",
    "    elif df[col].dtype == 'bool':\n",
    "        bool_list.append(col)\n",
    "    else:\n",
    "        num_list.append(col)\n",
    "        \n",
    "print(f'Object List:\\n{obj_list}\\n\\nNumeric List:\\n{num_list}\\n\\nBool List:\\n{bool_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d92750",
   "metadata": {},
   "source": [
    "### Columns I will need to update `dtype` for:\n",
    "- `case_ref_num` from numeric to object\n",
    "- `case_open` from object to datetype \n",
    "- `sla_due` from object to datetype \n",
    "- `case_close` from object to datetype \n",
    "- `council_distr` from number to object\n",
    "- `population` from object to integer\n",
    "    - remove `,` \n",
    "- `avg_inc`\n",
    "    - first need to remove `$` and `,`\n",
    "    - from object to float\n",
    "    \n",
    "    \n",
    " Also, `location` column is redudant, will drop that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb7359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to object\n",
    "df[['case_ref_num', 'council_distr']] = df[['case_ref_num', 'council_distr']].astype('O')\n",
    "\n",
    "# to datetime\n",
    "pd.to_datetime(df[['case_open', 'sla_due', 'case_close']], format = '%Y:%m:%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865a5b8",
   "metadata": {},
   "source": [
    "### I think I am getting this error because of null values\n",
    "I am going to drop null values and then come back to column dtype cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['case_open', 'sla_due', 'case_close']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d49ebe",
   "metadata": {},
   "source": [
    "### Let's take a look at null values...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = pd.concat([round(df.isna().sum().sort_values(ascending = False) / df.shape[0] * 100, 2), \\\n",
    "                     df.isna().sum().sort_values(ascending = False)], axis = 1).head(4)\n",
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3efc1",
   "metadata": {},
   "source": [
    "#### The null values are a very small percentage of the total data and I don't think I will lose a signficant amount info by dropping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e78504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39905e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verying there are no null values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b226309",
   "metadata": {},
   "source": [
    "#### Going to try the `datetime` dtype conversion again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b23336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to datetime\n",
    "pd.to_datetime(df[['case_open', 'sla_due', 'case_close']], format = '%Y:%m:%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782d78b",
   "metadata": {},
   "source": [
    "#### Still getting an error, but code works without `format` and doing each column individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9a0f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to datetime\n",
    "df.sla_due = pd.to_datetime(df.sla_due)\n",
    "df.case_open = pd.to_datetime(df.case_open)\n",
    "df.case_close = pd.to_datetime(df.case_close)\n",
    "\n",
    "# population from object to integer\n",
    "df.population = df.population.str.replace(',', '').astype(int)\n",
    "\n",
    "# to float\n",
    "df.avg_inc = df.avg_inc.str.replace('$', '').str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c259a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping location column\n",
    "df.drop(columns =  ['location'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd0e2ff",
   "metadata": {},
   "source": [
    "### For the last cleanup step I am feature engineering a new column `days_to_close`  \n",
    "- This will be how many days it took for the case to close\n",
    "- Derived from `case_closed` - `case_open`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting datetime to string\n",
    "# removing non-numeric endings\n",
    "# changing dtype to integer\n",
    "df['days_to_close'] = (df.case_close - df.case_open).astype('str').str.replace(' days', '').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c32b2",
   "metadata": {},
   "source": [
    "## Now to look at the columns and dtypes to verify cleanup and ready for explore..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5133122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811afc4",
   "metadata": {},
   "source": [
    "### I want to reset the `index` to get a continuous value. After dropping some data the numbers skip around..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880df7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.reset_index(inplace = True)\n",
    "\n",
    "df = df.rename(columns = {'index':'index_'}).drop(columns = ['level_0', 'index_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef797403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to be appended in for loop\n",
    "obj_list = []\n",
    "int_list = []\n",
    "float_list = []\n",
    "bool_list = []\n",
    "date_list = []\n",
    "\n",
    "# for loop to append df columns to corresponding lists\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() == 2:\n",
    "        bool_list.append(col)\n",
    "        \n",
    "    elif df[col].dtype == 'O':\n",
    "        obj_list.append(col)\n",
    "        \n",
    "    elif df[col].dtype == 'int':\n",
    "        int_list.append(col)\n",
    "\n",
    "    elif df[col].dtype == 'float':\n",
    "        float_list.append(col)\n",
    "    \n",
    "    else:\n",
    "        date_list.append(col)\n",
    "        \n",
    "print(f'Object List:\\n{obj_list}\\n\\nInteger List:\\n{int_list}\\n\\nBool List:\\n{bool_list}\\n\\nFloat List:\\n{float_list}\\n\\nDates List:\\n{date_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393cf2b",
   "metadata": {},
   "source": [
    "### I can also drop the `case_status` column since I removed all the null values for `case_close` \n",
    "- the only cases I will be looking at are the ones who have been closed as of the data report date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb37cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['case_close'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6c4dc",
   "metadata": {},
   "source": [
    "### also dropping the `case_ref_num` column since it is unique for each value (can use index as counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c53ced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns = ['case_ref_num'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f472fad",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "Target | Dtype | Description\n",
    ":--- | :--- | :---\n",
    "`days_to_close` | datetime | the total time in days it took to close the case; feature engineered from `close_date` - `open_date`\n",
    "\n",
    "\n",
    "Variable | Dtype |  Description\n",
    ":--- | :--- | :---\n",
    "`category` | object | top level 311 service request category\n",
    "`case_open` | datetime | the date a case was submitted\n",
    "`sla_due` | dtype | each service request `category` has a due date assigned to the request, based on the dept division `dept_div`\n",
    "`dept` | object | the City deaprtment to whom the case is assigned\n",
    "`dept_div` | object | the department division within the City deaprtment to whom the case is assigned\n",
    "`council_distr` | object | The Council District number from where the issue was reported\n",
    "`zip` | object | the zip code for the reported case/service requested\n",
    "`population` | int | the population for the zip code for the reported case/service requested\n",
    "`avg_inc` | float | the avergae income for the zip code for the reported case/service requested\n",
    "`lat` | float | the latitude coordinate for the zip code for the reported case/service requested\n",
    "`long` | float | the longitude coordinate for the zip code for the reported case/service requested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d2d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.days_to_close.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c13f85",
   "metadata": {},
   "source": [
    "### The last step in wrangling the data is splitting...\n",
    "For this pass I am not going to stratify\n",
    ">On the next pass I will come back and create a column with quartile bins for my target `days_to_close` and stratify on that variable column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ec7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# creating test dataset\n",
    "train_validate, test = train_test_split(df, test_size=.2, random_state=12)\n",
    "\n",
    "# creating the train and test datasets\n",
    "train, validate = train_test_split(train_validate, test_size=.3, random_state=12)\n",
    "\n",
    "# verifying the split\n",
    "print(f'train -> {train.shape}')\n",
    "print(f'validate -> {validate.shape}')\n",
    "print(f'test -> {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6cfe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544e04b",
   "metadata": {},
   "source": [
    "## df is ready for exploration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
